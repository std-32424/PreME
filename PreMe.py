# -*- coding: utf-8 -*-
"""Untitled18.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1eAp0t_WmKxiwIUHA-OIpRRHhtzVVz7H8
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

df = pd.read_csv('/content/predictive_maintenance.csv')

"""### Data Overview
Let's get a general understanding of the dataset's structure, including the number of entries, columns, data types, and non-null values.
"""

df.info()

"""### Descriptive Statistics
Next, let's look at the descriptive statistics for numerical columns, which will provide insights into their central tendency, dispersion, and shape.
"""

display(df.describe())

df.isnull().sum()

import pandas as pd
import xgboost as xgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, accuracy_score
from sklearn.preprocessing import LabelEncoder

# 1. LOAD DATA
# Assuming your file is named 'maintenance_data.csv'
df = pd.read_csv('/content/predictive_maintenance.csv')

df

# 2. CLEANING & PREPROCESSING
# Drop ID columns (UDI, Product ID) as they confuse the model
# Note: Adjust column names if they are slightly different in your full CSV
X = df.drop(['UDI', 'Product ID', 'Target', 'Failure Type'], axis=1)

X

# Encode the 'Type' column (L, M, H -> 0, 1, 2)
le_type = LabelEncoder()
X['Type'] = le_type.fit_transform(X['Type'])

# 3. STRATEGY STEP 1: BINARY MODEL (Failure vs Not)
y_binary = df['Target']
X_train, X_test, y_train, y_test = train_test_split(X, y_binary, test_size=0.2, random_state=42)

# Calculate weighting for imbalance (No Failure count / Failure count)
# This prevents the model from just guessing "0" every time
scale_pos_weight = (y_train == 0).sum() / (y_train == 1).sum()

model_binary = xgb.XGBClassifier(
    scale_pos_weight=scale_pos_weight,
    eval_metric='logloss',
    use_label_encoder=False
)

model_binary.fit(X_train_cleaned, y_train)

print("=== STEP 1: BINARY MODEL RESULTS ===")
# We verify if it can catch the failures
print(classification_report(y_test, model_binary.predict(X_test_cleaned)))

# 4. STRATEGY STEP 2: MULTI-CLASS MODEL (Failure Type)
# We filter the data to train ONLY on actual failures
train_failures = df[df['Target'] == 1].copy()
X_failures = train_failures.drop(['UDI', 'Product ID', 'Target', 'Failure Type'], axis=1)

# Apply column name cleaning to X_failures
X_failures = clean_col_names(X_failures.copy())

# Re-fit le_type on the original 'Type' column from df to ensure correct string-to-int mapping
# This addresses the potential state inconsistency of the previously fitted le_type
le_type_re_fit = LabelEncoder()
le_type_re_fit.fit(df['Type'])

# Transform the 'Type' column in X_failures using the correctly fitted encoder
X_failures['Type'] = le_type_re_fit.transform(X_failures['Type'])

# 4. STRATEGY STEP 2: MULTI-CLASS MODEL (Failure Type)
# We filter the data to train ONLY on actual failures
train_failures = df[df['Target'] == 1].copy()
X_failures = train_failures.drop(['UDI', 'Product ID', 'Target', 'Failure Type'], axis=1)

# Apply column name cleaning to X_failures for XGBoost compatibility
X_failures = clean_col_names(X_failures.copy())

# Use the correctly fitted encoder 'le_type_re_fit' from the previous cell (2t9sVHfUBlxt)
X_failures['Type'] = le_type_re_fit.transform(X_failures['Type'])

# Encode the text targets (e.g., "Heat Failure" -> 0, "Power Failure" -> 1)
y_failures_text = train_failures['Failure Type']
le_failure = LabelEncoder()
y_failures_encoded = le_failure.fit_transform(y_failures_text)

X_train_f, X_test_f, y_train_f, y_test_f = train_test_split(X_failures, y_failures_encoded, test_size=0.2, random_state=42)

model_type = xgb.XGBClassifier(
    objective='multi:softmax',
    num_class=len(le_failure.classes_),
    eval_metric='mlogloss',
    use_label_encoder=False
)

model_type.fit(X_train_f, y_train_f)

print("\n=== STEP 2: FAILURE TYPE MODEL RESULTS ===")
# Decode predictions back to text (0 -> "Overstrain Failure") to check results
preds = model_type.predict(X_test_f)
print(classification_report(y_test_f, preds, target_names=le_failure.classes_))

from sklearn.metrics import precision_score, recall_score

# Get the raw probability numbers (0.0 to 1.0) instead of just 0 or 1
y_probs = model_binary.predict_proba(X_test_cleaned)[:, 1]

# Try a lower threshold to catch more failures (Prioritize Recall)
threshold = 0.3  # If prob > 30%, call it a failure
y_pred_new = (y_probs > threshold).astype(int)

print(f"--- Threshold: {threshold} ---")
print(f"Precision: {precision_score(y_test, y_pred_new):.2f}")
print(f"Recall:    {recall_score(y_test, y_pred_new):.2f}")

import numpy as np
import pandas as pd
from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix

# 1. Get the probability of failure (0.0 to 1.0) for each row
# We take column [1] because that is the probability of "Class 1" (Failure)
y_probs = model_binary.predict_proba(X_test_cleaned)[:, 1]

# 2. Define the thresholds we want to test (0.1, 0.2 ... 0.9)
thresholds = np.arange(0.1, 1.0, 0.1)

results = []

print(f"{'Threshold':<10} | {'Recall (Catch Rate)':<20} | {'Precision (Trust)':<18} | {'F1-Score':<10} | {'False Alarms'}")
print("-" * 85)

for thresh in thresholds:
    # Apply the threshold
    y_pred_custom = (y_probs >= thresh).astype(int)

    # Calculate metrics
    rec = recall_score(y_test, y_pred_custom, zero_division=0)
    prec = precision_score(y_test, y_pred_custom, zero_division=0)
    f1 = f1_score(y_test, y_pred_custom, zero_division=0)

    # Count specific errors using Confusion Matrix
    # tn = true negative, fp = false positive (False Alarm), fn = false negative (Missed Failure), tp = true positive
    tn, fp, fn, tp = confusion_matrix(y_test, y_pred_custom).ravel()

    print(f"{thresh:.1f}        | {rec:.1%}               | {prec:.1%}             | {f1:.2f}       | {fp}")

print("-" * 85)

from sklearn.metrics import confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

# Get predictions from the binary classification model
y_pred_binary = model_binary.predict(X_test_cleaned)

# Create the confusion matrix
cm = confusion_matrix(y_test, y_pred_binary)

# Define labels for the confusion matrix (0: No Failure, 1: Failure)
labels = ['No Failure', 'Failure']

# Plot the confusion matrix
plt.figure(figsize=(6, 5))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.title('Confusion Matrix for Binary Classification (Failure vs. No Failure)')
plt.show()

print("Confusion Matrix:")
print(pd.DataFrame(cm, index=['True No Failure', 'True Failure'], columns=['Predicted No Failure', 'Predicted Failure']))

import joblib

class MaintenancePredictor:
    def __init__(self, binary_model, type_model, threshold=0.3):
        self.binary_model = binary_model
        self.type_model = type_model
        self.threshold = threshold
        # Hardcoded labels based on your encoder
        self.type_labels = ["Heat Failure", "No Failure", "Overstrain Failure", "Power Failure", "Tool Wear Failure"]

    def predict(self, new_data):
        # 1. Get Probability of Failure
        prob = self.binary_model.predict_proba(new_data)[:, 1]

        # 2. Apply Custom Threshold
        is_failure = (prob >= self.threshold).astype(int)

        results = []
        for i, failure_detected in enumerate(is_failure):
            if failure_detected == 0:
                results.append("Normal Operation")
            else:
                # 3. If Failure, predict the TYPE using the 2nd model
                # We need to reshape data for single prediction
                row = new_data.iloc[[i]]
                type_pred = self.type_model.predict(row)[0]
                results.append(f"ALERT: {self.type_labels[type_pred]}")

        return results

# --- SAVE YOUR WORK ---
# Create the final system
final_system = MaintenancePredictor(model_binary, model_type, threshold=0.3)

# Test it on 5 random rows from your test set
sample_data = X_test_cleaned.sample(5) # Changed from X_test.sample(5) to X_test_cleaned.sample(5)
print("=== LIVE PREDICTIONS ===")
print(final_system.predict(sample_data))

# Save to file (so you can load it in a web app or dashboard later)
joblib.dump(final_system, 'preventive_maintenance_system.pkl')
print("\nSystem saved as 'preventive_maintenance_system.pkl'")